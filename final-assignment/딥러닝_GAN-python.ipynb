{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_48\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_52 (InputLayer)        [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 3136)              316736    \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 3136)              12544     \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "reshape_18 (Reshape)         (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_36 (UpSampling (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_67 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_37 (UpSampling (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_68 (Conv2D)           (None, 28, 28, 1)         289       \n",
      "=================================================================\n",
      "Total params: 348,161\n",
      "Trainable params: 341,825\n",
      "Non-trainable params: 6,336\n",
      "_________________________________________________________________\n",
      "Model: \"model_49\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_53 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_69 (Conv2D)           (None, 28, 28, 64)        1664      \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_70 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 100353    \n",
      "=================================================================\n",
      "Total params: 351,746\n",
      "Trainable params: 175,873\n",
      "Non-trainable params: 175,873\n",
      "_________________________________________________________________\n",
      "Model: \"model_50\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_54 (InputLayer)        [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "model_48 (Model)             (None, 28, 28, 1)         348161    \n",
      "_________________________________________________________________\n",
      "model_49 (Model)             (None, 1)                 175873    \n",
      "=================================================================\n",
      "Total params: 524,034\n",
      "Trainable params: 341,825\n",
      "Non-trainable params: 182,209\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "(1, 100)\n",
      "(1, 1)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'dense_34_target' with dtype float and shape [?,?]\n\t [[{{node dense_34_target}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-5fc59552ec5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;31m#    res_gan = gan.train_on_batch(fake[0], real_1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m     \u001b[0mres_gan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1173\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'dense_34_target' with dtype float and shape [?,?]\n\t [[{{node dense_34_target}}]]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Reshape, Flatten\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.layers import Activation, LeakyReLU\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "np.random.seed(0)\n",
    "#tf.random.set_seed(0)\n",
    "tf.random.set_random_seed(0)\n",
    "\n",
    "\n",
    "# 데이터 불러오기\n",
    "(X_raw, _), (_, _) = mnist.load_data()\n",
    "\n",
    "# 변수 설정\n",
    "n_img = X_raw.shape[0]\n",
    "epoch = 3000\n",
    "#n_batch = 100\n",
    "n_batch = 1\n",
    "\n",
    "\n",
    "# 데이터 전처리\n",
    "X_re = X_raw.reshape(n_img, 28, 28, 1)\n",
    "scale_c = 255/2\n",
    "X = (X_re - scale_c) / scale_c\n",
    "real_1 = np.ones((n_batch, 1))\n",
    "\n",
    "fake_0 = np.zeros((n_batch, 1))\n",
    "\n",
    "# 생성자\n",
    "input_layer1 = Input(shape=(100,))\n",
    "x1 = Dense(64*7*7)(input_layer1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = Activation(LeakyReLU(0.3))(x1)\n",
    "x1 = Reshape((7,7,64))(x1)\n",
    "x1 = UpSampling2D()(x1)\n",
    "x1 = Conv2D(32, kernel_size=(3,3), padding='same')(x1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = Activation(LeakyReLU(0.3))(x1)\n",
    "x1 = UpSampling2D()(x1)\n",
    "output_layer1 = Conv2D(1, kernel_size=(3,3), padding='same', activation='tanh')(x1)\n",
    "generator = Model(input_layer1, output_layer1)\n",
    "generator.summary()\n",
    "\n",
    "# 판별자\n",
    "#input_layer2 = Input(shape=(28, 28, 1))\n",
    "input_layer2 = Input(shape=(28, 28, 1))\n",
    "\n",
    "x2 = Conv2D(64, kernel_size=(5,5), padding='same')(input_layer2)\n",
    "x2 = Activation(LeakyReLU(0.3))(x2)\n",
    "x2 = Dropout(0.25)(x2)\n",
    "x2 = Conv2D(128, kernel_size=(3,3), padding='same')(x2)\n",
    "x2 = Activation(LeakyReLU(0.3))(x2)\n",
    "x2 = Dropout(0.25)(x2)\n",
    "x2 = Flatten()(x2)\n",
    "output_layer2 = Dense(1, activation='sigmoid')(x2)\n",
    "discriminator = Model(input_layer2, output_layer2)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "discriminator.trainable = False\n",
    "\n",
    "\n",
    "discriminator.summary()\n",
    "\n",
    "# GAN\n",
    "input_gan = Input(shape=(100,))\n",
    "output_dis = discriminator(generator(input_gan))\n",
    "gan = Model(input_gan, output_dis)\n",
    "gan.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "gan.summary()\n",
    "\n",
    "# 학습\n",
    "loss_disc_real = [0]*epoch\n",
    "loss_disc_fake = [0]*epoch\n",
    "loss_disc_avg = [0]*epoch\n",
    "loss_gan = [0]*epoch\n",
    "acc_disc_real = [0]*epoch\n",
    "acc_disc_fake = [0]*epoch\n",
    "acc_disc_avg = [0]*epoch\n",
    "acc_gan = [0]*epoch\n",
    "\n",
    "for i in range(0, epoch):\n",
    "    # 실제 데이터 판별\n",
    "    idx = np.random.randint(0, n_img, n_batch)\n",
    "    imgs = X[idx]\n",
    "    res_real = discriminator.train_on_batch(imgs, real_1)\n",
    "    \n",
    "    # 가짜 데이터 생성 및 판별\n",
    "#    fake = np.random.normal(0, 1, size=(n_batch, 100))\n",
    "    fake = np.random.normal(0,1, size=(n_batch, 100))\n",
    "\n",
    "    gen_imgs = generator.predict(fake)\n",
    "    res_fake = discriminator.train_on_batch(gen_imgs, fake_0)\n",
    "    \n",
    "    # 판별 손실 평균 & 정확도 평균\n",
    "    loss_disc_avg_ith = np.add(res_real[0],res_fake[0])*0.5\n",
    "    acc_disc_avg_ith = np.add(res_real[1],res_fake[1])*0.5\n",
    "    \n",
    "    # GAN 결과\n",
    "    print(fake.shape)\n",
    "    print(real_1.shape)\n",
    "\n",
    "#    res_gan = gan.train_on_batch(fake[0], real_1)\n",
    "    res_gan = gan.train_on_batch(fake, real_1)\n",
    "\n",
    "\n",
    "\n",
    "    # 정확도 및 손실\n",
    "    loss_disc_real[i] = res_real[0]\n",
    "    loss_disc_fake[i] = res_fake[0]\n",
    "    loss_disc_avg[i] = loss_disc_avg_ith\n",
    "    loss_gan[i] = res_gan[0]\n",
    "    \n",
    "    acc_disc_real[i] = res_real[1]\n",
    "    acc_disc_fake[i] = res_fake[1]\n",
    "    acc_disc_avg[i] = acc_disc_avg_ith\n",
    "    acc_gan[i] = res_gan[1]\n",
    "    \n",
    "    print('epoch:%d'%i,\n",
    "          ' 판별손실평균:%.4f'%loss_disc_avg_ith,\n",
    "          ' 판별정확도평균:%.4f'%acc_disc_avg_ith,\n",
    "          ' 생성손실:%.4f'%res_gan[0], \n",
    "          ' 생성정확도:%.4f'%res_gan[1])\n",
    "\n",
    "# 손실 그래프\n",
    "epo = np.arange(0, epoch)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epo, loss_disc_real,'y:',label='disc_real')\n",
    "plt.plot(epo, loss_disc_fake,'g-.',label='disc_fake')\n",
    "plt.plot(epo, loss_disc_avg,'b--',label='disc_avg')\n",
    "plt.plot(epo, loss_gan,'r',label='generator')\n",
    "plt.title('LOSS')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 정확도 그래프\n",
    "plt.figure()\n",
    "plt.plot(epo, acc_disc_real,'y:',label='disc_real')\n",
    "plt.plot(epo, acc_disc_fake,'g-.',label='disc_fake')\n",
    "plt.plot(epo, acc_disc_avg,'b--',label='disc_avg')\n",
    "plt.plot(epo, acc_gan,'r',label='generator')\n",
    "plt.title('ACCURACY')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# epoch=3000\n",
    "gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(3*5):\n",
    "    plt.subplot(3, 5, i+1)\n",
    "    plt.imshow(gen_imgs[i].reshape((28, 28)), cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "## The dimension of the Prior Noise Signal is 100 \n",
    "## The generator would have 150 and 300 hidden units successively before 784 outputs corresponding\n",
    "## to 28x28 image size\n",
    "\n",
    "h1_dim = 150\n",
    "h2_dim = 300\n",
    "dim = 100\n",
    "batch_size = 256\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "# Define the generator - take noise and convert them to images\n",
    "#--------------------------------------------------------------\n",
    "def generator_(z_noise):\n",
    "    w1 = tf.Variable(tf.truncated_normal([dim,h1_dim], stddev=0.1), name=\"w1_g\", dtype=tf.float32)\n",
    "    b1 = tf.Variable(tf.zeros([h1_dim]), name=\"b1_g\", dtype=tf.float32)\n",
    "    h1 = tf.nn.relu(tf.matmul(z_noise, w1) + b1)\n",
    "    w2 = tf.Variable(tf.truncated_normal([h1_dim,h2_dim], stddev=0.1), name=\"w2_g\", dtype=tf.float32)\n",
    "    b2 = tf.Variable(tf.zeros([h2_dim]), name=\"b2_g\", dtype=tf.float32)\n",
    "    h2 = tf.nn.relu(tf.matmul(h1, w2) + b2)\n",
    "    w3 = tf.Variable(tf.truncated_normal([h2_dim,28*28],stddev=0.1), name=\"w3_g\", dtype=tf.float32)\n",
    "    b3 = tf.Variable(tf.zeros([28*28]), name=\"b3_g\", dtype=tf.float32)\n",
    "    h3 = tf.matmul(h2, w3) + b3\n",
    "    out_gen = tf.nn.tanh(h3)\n",
    "    weights_g = [w1, b1, w2, b2, w3, b3]\n",
    "    return out_gen,weights_g\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Define the Discriminator - take both real images  and synthetic fake images \n",
    "# from Generator and classify the real and fake images properly\n",
    "#---------------------------------------------------------------------------\n",
    "def discriminator_(x,out_gen,keep_prob):\n",
    "    x_all = tf.concat([x,out_gen], 0)\n",
    "    w1 = tf.Variable(tf.truncated_normal([28*28, h2_dim], stddev=0.1), name=\"w1_d\", dtype=tf.float32)\n",
    "    b1 = tf.Variable(tf.zeros([h2_dim]), name=\"b1_d\", dtype=tf.float32)\n",
    "    h1 = tf.nn.dropout(tf.nn.relu(tf.matmul(x_all, w1) + b1), keep_prob)\n",
    "    w2 = tf.Variable(tf.truncated_normal([h2_dim, h1_dim], stddev=0.1), name=\"w2_d\", dtype=tf.float32)\n",
    "    b2 = tf.Variable(tf.zeros([h1_dim]), name=\"b2_d\", dtype=tf.float32)\n",
    "    h2 = tf.nn.dropout(tf.nn.relu(tf.matmul(h1,w2) + b2), keep_prob)\n",
    "    w3 = tf.Variable(tf.truncated_normal([h1_dim, 1], stddev=0.1), name=\"w3_d\", dtype=tf.float32)\n",
    "    b3 = tf.Variable(tf.zeros([1]), name=\"d_b3\", dtype=tf.float32)\n",
    "    h3 = tf.matmul(h2, w3) + b3\n",
    "    y_data = tf.nn.sigmoid(tf.slice(h3, [0, 0], [batch_size, -1], name=None))\n",
    "    y_fake = tf.nn.sigmoid(tf.slice(h3, [batch_size, 0], [-1, -1], name=None))\n",
    "    weights_d = [w1, b1, w2, b2, w3, b3]\n",
    "    return y_data,y_fake,weights_d\n",
    "\n",
    "\n",
    "\n",
    "# Read the MNIST datadet\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "## Place holder for the real images\n",
    "x = tf.placeholder(tf.float32, [batch_size, 28*28], name=\"x_data\")\n",
    "## Place holder for the noise\n",
    "z_noise = tf.placeholder(tf.float32, [batch_size,dim], name=\"z_prior\")\n",
    "## Dropout probability\n",
    "keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "# generate the output op for generator and also define the weights.\n",
    "out_gen,weights_g = generator_(z_noise)\n",
    "# Define the ops and weights for Discriminator\n",
    "y_data, y_fake,weights_d = discriminator_(x,out_gen,keep_prob)\n",
    "## Cost function for Discriminator\n",
    "discr_loss = -1*tf.reduce_mean(tf.log(y_data) + tf.log(1 - y_fake))\n",
    "## Cost function for Generator\n",
    "gen_loss = -1*tf.reduce_mean( tf.log(y_fake))\n",
    "optimizer = tf.train.AdamOptimizer(0.0001)\n",
    "d_trainer = optimizer.minimize(discr_loss,var_list=weights_d)\n",
    "g_trainer = optimizer.minimize(gen_loss,var_list=weights_g)\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "z_sample = np.random.uniform(-1, 1, size=(batch_size,dim)).astype(np.float32)\n",
    "\n",
    "for i in range(60000):\n",
    "    batch_x, _ = mnist.train.next_batch(batch_size)\n",
    "    x_value = 2*batch_x.astype(np.float32) - 1\n",
    "    z_value = np.random.uniform(-1, 1, size=(batch_size,dim)).astype(np.float32)\n",
    "    sess.run(d_trainer,feed_dict={x:x_value, z_noise:z_value,keep_prob:0.7})\n",
    "    sess.run(g_trainer,feed_dict={x:x_value, z_noise:z_value,keep_prob:0.7})\n",
    "    if (i % 1000 == 0) and(i > 1000):\n",
    "        c1,c2 = sess.run([discr_loss,gen_loss],feed_dict={x:x_value, z_noise:z_value,keep_prob:0.7})\n",
    "        print ('iter:',i,'cost of discriminator',c1, 'cost of generator',c2)\n",
    "out_val_img = sess.run(out_gen,feed_dict={z_noise:z_sample})     \n",
    "img = 0.5*(out_val_img[3,:] + 1)\n",
    "img = np.reshape(img,(28,28))\n",
    "plt.imshow(img*255)\n",
    "saver.save(sess, \"newgan_\",global_step=i)\n",
    "imgs = 0.5*(out_val_img + 1)\n",
    "for k in range(36):\n",
    "    plt.subplot(6,6,k+1)\n",
    "    image = np.reshape(imgs[k],(28,28))\n",
    "    plt.imshow(image,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
